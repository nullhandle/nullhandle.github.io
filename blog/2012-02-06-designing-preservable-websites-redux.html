<!DOCTYPE html>
<html lang="en">
  <head>
    <link href="https://fonts.googleapis.com/css?family=Open+Sans" rel="stylesheet" type="text/css" />
    <link href="http://purl.org/dc/elements/1.1/" rel="schema.dc" />
    <link href="../css/responsive-nav.css" rel="stylesheet" type="text/css" />
    <link href="../css/stylesheet.css" rel="stylesheet" type="text/css" />
    <link href="../img/favicon.ico" rel="icon" type="image/x-icon" />
    <meta charset="UTF-8" />
    <meta name="DC.Contributor.PersonalName" content="Butch Lazorchak" />
    <meta name="DC.Creator.PersonalName" content="Nicholas Taylor" />
    <meta name="DC.Date" content="2012-02-06" scheme="W3CDTF" />
    <meta name="DC.Format" content="text/html" scheme="IMT" />
    <meta name="DC.Language" content="en-US" scheme="RFC4646" />
    <meta name="DC.Rights" content="https://creativecommons.org/licenses/by-sa/4.0/" scheme="URL" />
    <meta name="DC.Source" content="https://nullhandle.org/" scheme="URL" />
    <meta name="DC.Title" content="Designing Preservable Websites, Redux" />
    <meta name="DC.Type" content="blogPost" />
    <!-- Global Site Tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-194659-2" type="text/javascript"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments)};
      gtag('js', new Date());
      gtag('config', 'UA-194659-2', { 'anonymize_ip': true });
    </script>
    <script src="../js/responsive-nav.js" type="text/javascript"></script>
    <title>Designing Preservable Websites, Redux</title>
  </head>
  <body itemscope itemtype="http://schema.org/WebPage">
    <div class="border"></div>
    <nav class="nav-collapse" id="nav">
      <ul>
        <li><a href="../index.html">Home</a></li>
        <li><a href="../biography.html">Biography</a></li>
        <li><a href="../resume.html">R&eacute;sum&eacute;</a></li>
        <li class="active"><a href="index.html">Blog</a></li>
        <li><a href="../contact.html">Contact</a></li>
      </ul>
    </nav>
    <div class="content" itemscope itemtype="http://schema.org/BlogPosting">
      <h2 itemprop="headline">Designing Preservable Websites, Redux</h2>
      <div class="byline">Published by <span itemprop="author publisher" itemscope itemtype="http://schema.org/Person"><span itemprop="name"><a href="../biography.html" itemprop="url" rel="author"><span itemprop="givenName">Nicholas</span> <span itemprop="familyName">Taylor</span></a></span></span> on <time datetime="2017-09-29T19:23:00-07:00" itemprop="dateModified" /><time datetime="2012-02-06T14:55:51+00:00" itemprop="datePublished">6 February 2012</time></div>
      <br />
      <div itemprop="articleBody">
        <div>As much as we can do to <a href="https://blogs.loc.gov/digitalpreservation/2011/08/web-archive-preservation-planning/">preserve archived websites</a> once we have them, the challenges we encounter are always already determined by how those websites were originally constructed. In the interest of giving <a href="https://www.loc.gov/webarchiving/index.html">us</a> and <a href="https://en.wikipedia.org/w/index.php?title=List_of_Web_archiving_initiatives&amp;oldid=472217918">others</a> the best possible chance of preserving your online content, I wanted to follow on an <a href="https://siarchives.si.edu/blog/five-tips-designing-preservable-websites">excellent blog post</a> by <a href="http://www.robincamille.com/about/">Robin Davis</a> (previously) of the <a href="https://siarchives.si.edu/">Smithsonian Institution Archives</a> on the topic of designing preservable websites. Here are some best practices to keep in mind:</div>
        <br />
        <div>1) Follow web standards and accessibility guidelines.</div>
        <br />
        <div>Following <a href="https://www.w3.org/standards/">web standards</a> and <a href="https://www.w3.org/WAI/guid-tech.html">accessibility</a> <a href="http://www.section508.gov/index.cfm?fuseAction=developer">guidelines</a> is useful for reasons beyond web archiving, namely, <a href="https://en.wikipedia.org/w/index.php?title=Universal_usability&amp;oldid=470277583">(universal) usability</a> and <a href="https://en.wikipedia.org/w/index.php?title=Search_engine_optimization&amp;oldid=474914027">SEO</a>. It also facilitates better website archiving and replay. Because web crawlers, including the archival <a href="https://en.wikipedia.org/w/index.php?title=Heritrix&amp;oldid=461320489">Heritrix crawler</a>, access websites in a manner <a href="https://www.google.com/support/webmasters/bin/answer.py?answer=35769#2">similar to a text browser</a>, accessible websites are friendlier to web crawlers. Adherence to <a href="https://www.w3.org/standards/">web standards</a> makes for fewer cumulative idiosyncrasies that the <a href="https://en.wikipedia.org/w/index.php?title=Wayback_Machine&amp;oldid=475037483">Wayback Machine</a> must <a href="https://en.wikipedia.org/w/index.php?title=W3C_Markup_Validation_Service&amp;oldid=449780385#Browser_accommodation">accommodate</a> over time in rendering archived websites.</div>
        <br />
        <figure class="figure-left" itemprop="image" itemscope itemtype="https://schema.org/ImageObject" xmlns:cc="http://creativecommons.org/ns#" xmlns:dct="http://purl.org/dc/terms/">
          <img alt="Broken Chain" height="240" itemprop="url" src="https://farm4.staticflickr.com/3635/5800023505_f5983d76cd_n.jpg" width="320" />
          <meta itemprop="height" content="240" />
          <meta itemprop="width" content="320" />
          <figcaption>"<a href="https://www.flickr.com/photos/goforchris/5800023505/" property="dct:title">Lascaux cave painting</a>" by <a href="https://www.flickr.com/photos/goforchris/" property="cc:attributionName" rel="cc:attributionURL dct:creator">Christine McIntosh</a> under <a href="https://creativecommons.org/licenses/by-nd/2.0/" rel="license">CC BY-ND 2.0</a></figcaption>
        </figure>
        <div>2) Be careful with robots.txt exclusions.</div>
        <br />
        <div>Certain types of instructions entered into <a href="https://en.wikipedia.org/w/index.php?title=Robots_exclusion_standard&amp;oldid=474770491">robots.txt</a> may at once be fine for search engine crawlers but prevent archival crawlers from capturing content that is crucial for a faithful reproduction of the website. For example, instructing crawlers to stay out of a website's CSS and JavaScript directories wouldn't detract significantly from the quality of a search engine index, but it would make a big difference in the quality of an archival capture.</div>
        <br />
        <div>3) Use a site map, transparent links, and contiguous navigation.</div>
        <br />
        <div>A crawler can only capture webpages that it knows about. It discovers webpages by traversing links, meaning that it can ultimately only ever capture pages that are accessible by following links alone. A corollary is that a user browsing an archived website can only navigate by following links, because server-side functionalities like search don't work in the archive. Avoid relying on Flash, JavaScript, or other techniques that tend to obfuscate links as the sole means of navigating to any specific page, and consider creating a comprehensive <a href="https://en.wikipedia.org/w/index.php?title=Site_map&amp;oldid=472800796">site map</a> to ensure that the crawler doesn't miss anything.</div>
        <br />
        <div>4) Maintain stable URIs and redirect when necessary.</div>
        <br />
        <div>The stability of the Library of Congress' URI over time makes it possible to view website captures from 1997 to present in a <a href="https://wayback.archive.org/web/*/http://www.loc.gov/">single unbroken timeline</a> in the <a href="https://www.archive.org/web/web.php">Internet Archive Wayback Machine</a>. It also means that any individual bookmarks saved or inbound links published and circulated continue to work as they always have. <a href="https://en.wikipedia.org/w/index.php?title=Link_rot&amp;oldid=473553109">Link rot</a> on the web generally is, by unfortunate contrast, <a href="https://blogs.loc.gov/digitalpreservation/2011/11/the-average-lifespan-of-a-webpage/">altogether common</a>.</div>
        <br />
        <div>When a URI changes and a redirect to the new resource location isn't put in place, it decreases the likelihood that the new URI will be archived and almost assures that access to the website archives from prior to the URI change will be disassociated from those following. Web archiving tools' sensitivity to URI stability also means that URIs containing <a href="https://en.wikipedia.org/w/index.php?title=Session_ID&amp;oldid=474038232">session IDs</a> may be similarly dissociated from earlier captures of the same resource.</div>
        <br />
        <div>5) Consider using a Creative Commons license.</div>
        <br />
        <div>Pending changes to the U.S. copyright statute <a href="http://www.section108.gov/">to address digital preservation needs</a>, <a href="https://www.loc.gov/webarchiving/faq.html#faqs_33">we must request permission</a> from most website owners to re-display their crawled website outside of the Library of Congress and/or to even crawl their website in the first place. The Library of Congress is but one of a number of <a href="http://www.webarchive.org.uk/ukwa/info/faq#FAQ9">web</a> <a data-originalurl="http://www.ndl.go.jp/en/cdnlao/newsletter/066/661.html" data-versiondate="2013-01-06" href="https://web.archive.org/web/20130106064653/http://www.ndl.go.jp/en/cdnlao/newsletter/066/661.html">archiving</a> <a href="http://library.columbia.edu/indiv/humanrights/hrwa/faq.html">institutions</a> that must solicit permissions. A website published under a <a href="https://creativecommons.org/">Creative Commons</a> license provides an affirmative permission to be crawled and preserved.</div>
        <br />
        <figure class="figure-right" itemprop="image" itemscope itemtype="https://schema.org/ImageObject" xmlns:cc="http://creativecommons.org/ns#" xmlns:dct="http://purl.org/dc/terms/">
          <img alt="404 Page: Book Shelf" height="320" itemprop="url" src="https://farm4.staticflickr.com/3562/3323310397_ed4243743e_n.jpg" width="213" />
          <meta itemprop="height" content="320" />
          <meta itemprop="width" content="213" />
          <figcaption>"<a href="https://www.flickr.com/photos/herzogbr/1381124074/" property="dct:title">Rosetta Stone_British Museum_2475</a>" by <a href="https://www.flickr.com/photos/kitlogan/" property="cc:attributionName" rel="cc:attributionURL dct:creator">Kit Logan</a> under <a href="https://creativecommons.org/licenses/by-nc-nd/2.0/" rel="license">CC BY-NC-ND 2.0</a></figcaption>
        </figure>
        <div>6) Use sustainable data formats.</div>
        <br />
        <div>Though a webpage is presented as a unified experience, it consists of many different files and file types. A commitment to preserving that experience therefore implies a commitment to managing the potentially distinct preservation risks of all the component file types. When deciding what types of code and file formats to use in building a website, <a href="https://en.wikipedia.org/w/index.php?title=Open_standard&amp;oldid=471550210">open standards</a> and <a href="https://en.wikipedia.org/w/index.php?title=Open_format&amp;oldid=463379844">open file formats</a> are generally the best choices for preservation. The exception is when the open format is either <a href="https://fileformats.wordpress.com/2011/12/20/undocumented-open-formats/">poorly-documented</a> or allows for <a href="https://filesthatlast.wordpress.com/2011/12/20/obsolete-files/">vendor-specific extensions</a> â€“ these may well be worse than well-documented proprietary formats that are widely-implemented in a uniform way. The <a href="http://www.digitalpreservation.gov/formats/">Sustainability of Digital Formats website</a> outlines a <a href="https://www.digitalpreservation.gov/formats/intro/format_eval_rel.shtml#factors">number of criteria</a> that make for a truly "sustainable" format besides ostensible "openness."</div>
        <br />
        <div>7) Embed metadata, especially the character encoding.</div>
        <br />
        <div>Since web servers <a href="https://www.w3.org/TR/html4/charset.html#h-5.2.2">don't reliably report</a> <a href="https://www.w3.org/QA/2008/03/html-charset.html">character encoding</a>, it is important that pages do so. Use an <a href="https://www.w3.org/TR/html401/struct/global.html#adef-http-equiv">HTML meta tag</a> or <a href="http://www.w3.org/TR/REC-xml/#NT-EncodingDecl">XML doctype declaration</a> to indicate what encoding should be used to render the page. Additional embedded metadata is useful both for <a href="https://en.wikipedia.org/w/index.php?title=Search_engine_optimization&amp;oldid=474914027">SEO</a> and for <a href="https://en.wikipedia.org/w/index.php?title=Digital_curation&amp;oldid=472995693">curated</a> collections of web archives, such as <a href="http://lcweb2.loc.gov/diglib/lcwa/html/lcwa-home.html">those maintained by the Library of Congress</a> which draw upon site-provided metadata for <a href="https://www.w3.org/2001/sw/wiki/Library_terminology_informally_explained#access_point">access points</a>.</div>
        <br />
        <div>8) Use archiving-friendly platform providers and content management systems.</div>
        <br />
        <div>While <a href="https://en.wikipedia.org/w/index.php?title=List_of_social_networking_websites&amp;oldid=475279142">platform providers</a> have incentives to permit commercial search indexers to access at least some of the content they host, they are not always so accommodating of archival crawlers. If the archivability of your website is important, examine the company's robots.txt or inquire about their policies before committing to their platform. Also, even if a company doesn't block archival crawlers outright, the website templates or content management systems they utilize may not archive well. Look at how other websites built on the same platform replay in <a href="https://www.archive.org/web/web.php">Internet Archive's Wayback Machine</a>, and, if you're using an open source content management system, be sure to review the configuration of any bundled robots.txt.</div>
        <br />
        <div>While adhering to these recommendations won't guarantee a high-quality archival capture and subsequent flawless preservation of your website, not following them will ensure additional archiving and preservation challenges.</div>
      </div>
      <br />
      <div class="byline"><a href="http://nullhandle.org/blog/2012-02-06-designing-preservable-websites-redux.html" rel="canonical">Permalink</a> | <a href="https://blogs.loc.gov/digitalpreservation/2012/02/designing-preservable-websites-redux/">Crossposted</a> to <a href="https://blogs.loc.gov/thesignal/">The Signal</a><a href="https://creativecommons.org/licenses/by-sa/4.0/" rel="license"><img alt="Creative Commons Attribution-ShareAlike 4.0 International License" class="copyright" height="15" src="https://i.creativecommons.org/l/by-sa/4.0/80x15.png" width="80" /></a></div>
      <br />
      <script>
        var nav = responsiveNav(".nav-collapse");
      </script>
    </div>
  </body>
</html>